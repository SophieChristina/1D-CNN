{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from scipy import linalg, optimize, constants, interpolate, special, stats\n",
    "import math as ma\n",
    "from math import exp, pow, sqrt, log\n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import keras\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "import sklearn as sl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3160, 1, 1)\n",
      "Training data shape :  (14, 3160, 1, 1) (14,)\n",
      "Testing data shape :  (6, 3160, 1, 1) (6,)\n",
      "-----------------\n",
      "inputs_train max :  1811.3118\n",
      "inputs_test max :  424.6451\n",
      "-----------------\n",
      "inputs_train max (skaliert):  1.0\n",
      "inputs_test max (skaliert):  1.0\n",
      "-----------------\n",
      "1.0\n",
      "[0. 1.]\n",
      "0.0\n",
      "[1. 0.]\n",
      "1.0\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# csv einlesen\n",
    "Vein = pd.read_csv('datensatz/vein.csv')\n",
    "# dataframe draus machen\n",
    "df = pd.DataFrame(Vein)\n",
    "\n",
    "#inputs und targets generieren (Spalte 1 für die Targets, Spalte 2 bis Ende für die Inputs)\n",
    "inputs = df.iloc[1:, 2:].values\n",
    "targets = df.iloc[1:, 1].values\n",
    "\n",
    "inputs = inputs.reshape(inputs.shape[0],3160,1,1).astype( 'float32' )\n",
    "print(inputs.shape)\n",
    "\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, test_size = 0.3)\n",
    "\n",
    "\n",
    "#(Anzahl Datenpunkte, Höhe, Breite, Kanäle)  \n",
    "print('Training data shape : ', inputs_train.shape, targets_train.shape)\n",
    "print('Testing data shape : ', inputs_test.shape, targets_test.shape)\n",
    "\n",
    "print('-----------------')\n",
    "\n",
    "# INPUTS\n",
    "inputs_train_max = inputs_train[0].max()\n",
    "inputs_test_max = inputs_test[0].max()\n",
    "\n",
    "print('inputs_train max : ', inputs_train_max)\n",
    "print('inputs_test max : ', inputs_test_max)\n",
    "\n",
    "print('-----------------')\n",
    "\n",
    "inputs_train_scaled = inputs_train/inputs_train_max\n",
    "inputs_test_scaled = inputs_test/inputs_test_max\n",
    "\n",
    "print('inputs_train max (skaliert): ', inputs_train_scaled[0].max())\n",
    "print('inputs_test max (skaliert): ', inputs_test_scaled[0].max())\n",
    "\n",
    "print('-----------------')\n",
    "\n",
    "#TARGETS\n",
    "targets_train_categorial = to_categorical(targets_train)\n",
    "targets_test_categorial = to_categorical(targets_test)\n",
    "\n",
    "print(targets_train[0])\n",
    "print(targets_train_categorial[0])\n",
    "\n",
    "print(targets_train[1])\n",
    "print(targets_train_categorial[1])\n",
    "\n",
    "print(targets_train[2])\n",
    "print(targets_train_categorial[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D CNN definieren: \n",
    "def evaluate_model(inputs_train, targets_train, inputs_test, targets_test): #inputs_train = trainX, targets_train = trainy\n",
    "\tverbose, epochs, batch_size = 1, 10, 14\n",
    "\tn_timesteps, n_features, n_outputs = inputs_train.shape[1], inputs_train.shape[2], targets_train.shape[1]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling1D(pool_size=2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit(inputs_train, targets_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(inputs_test, targets_test, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "\tprint(scores)\n",
    "\tm, s = mean(scores), std(scores)\n",
    "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "\t# load data\n",
    "\tinputs_train, targets_train, inputs_test, targets_test= load_dataset()\n",
    "\t# repeat experiment\n",
    "\tscores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\tscore = evaluate_model(inputs_train, targets_train, inputs_test, targets_test)\n",
    "\t\tscore = score * 100.0\n",
    "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
    "\t\tscores.append(score)\n",
    "\t# summarize results\n",
    "\tsummarize_results(scores)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autoencoder \n",
    "\n",
    "def autoencoder (input_img):\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv1D(50, 12, activation = 'relu', padding = 'same')(input_layer)\n",
    "encoder = MaxPooling1D(4, padding = 'same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = Conv1D(50, 12, activation = 'relu', padding = 'same')(encoder)\n",
    "decoder = UpSampling1D(4)(decoder)\n",
    "decoder = Conv1D(4, 12, activation = 'relu', padding = 'same')(decoder)\n",
    "\n",
    "autoencoder = Model(input_img, autoencoder(input_img))\n",
    "autoencoder.compile(loss='mean-squared-error', optimizer = RMSprop())\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the autoencoder\n",
    "autoencoder_train = autoencoder.fit(inputs_train_scaled, targets_train_categorial, \n",
    "          epochs=5,\n",
    "          batch_size=14,\n",
    "          verbose=1,\n",
    "          validation_data=(inputs_test_scaled, targets_test_categorial),  \n",
    "          callbacks=[plot_losses])\n",
    "\n",
    "\n",
    "print(veinModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Training vs. Validation Loss\n",
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on Test Data \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
